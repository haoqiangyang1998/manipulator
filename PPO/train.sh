#!/bin/bash
#python train.py --headless-mode --train --code-version mani_40 --gamma 0.99 --plane-model
#python train.py --headless-mode --train --code-version mani_41 --gamma 0.9 --plane-model
#python train.py --headless-mode --train --code-version mani_42 --gamma 0.8 --plane-model
#python train.py --headless-mode --train --code-version mani_43 --gamma 0.6 --plane-model
#python train.py --headless-mode --train --code-version mani_44 --gamma 0.8 --goal-set 'easy'
#python train.py --headless-mode --train --code-version mani_45 --gamma 0.8 --goal-set 'hard'
#python train.py --headless-mode --train --code-version mani_46 --gamma 0.8 --goal-set 'super hard'
#python train.py --headless-mode --train --code-version mani_47 --gamma 0.8 --goal-set 'hard' --max-episode-steps 20
#python train.py --headless-mode --train --code-version mani_48 --gamma 0.8 --goal-set 'hard' --max-episode-steps 30
#python train.py --headless-mode --train --code-version mani_49 --gamma 0.8 --goal-set 'hard' --max-episode-steps 50
#python train.py --headless-mode --train --code-version mani_50 --gamma 0.8 --goal-set 'hard' --batch-size 16
#python train.py --headless-mode --train --code-version mani_51 --gamma 0.8 --goal-set 'hard' --batch-size 64
#python train.py --headless-mode --train --code-version mani_52 --gamma 0.8 --goal-set 'hard' --batch-size 128
#python train.py --headless-mode --train --code-version mani_53 --gamma 0.99 --max-episode-steps 20
#python train.py --train --code-version mani_54 --gamma 0.9 --max-episode-steps 20
#python train.py --train --code-version mani_55 --gamma 0.8 --max-episode-steps 20
#python train.py --train --code-version mani_56 --gamma 0.6 --max-episode-steps 20 --headless-mode &
#python train.py --train --code-version mani_57 --gamma 0.0 --max-episode-steps 20 --headless-mode &
#python train.py --train --code-version mani_58 --gamma 0.8 --max-episode-steps 30 --headless-mode --goal-set random --num-episodes 20000
#python train.py --train --code-version mani_59 --gamma 0.95 --max-episode-steps 100 --headless-mode --goal-set hard --num-episodes 2000
#python train.py --train --headless-mode --goal-set "super hard" --eval-goal-set "super hard" --plane-model --code-version mani_66 --gamma 0.95 --reward-type "dense potential"
#python train.py --train --headless-mode --goal-set "super hard" --eval-goal-set "super hard" --plane-model --code-version mani_67 --gamma 0.8 --reward-type "dense potential"
#python train.py --train --headless-mode --goal-set "super hard" --eval-goal-set "super hard" --plane-model --code-version mani_68 --gamma 0.6 --reward-type "dense potential"
#python train.py --train --headless-mode --goal-set "super hard" --eval-goal-set "super hard" --plane-model --code-version mani_69 --gamma 0.95 --reward-type "dense potential"
#python train.py --train --headless-mode --goal-set "super hard" --eval-goal-set "super hard" --plane-model --code-version mani_70 --gamma 0.8 --reward-type "dense potential"
#python train.py --train --headless-mode --goal-set "super hard" --eval-goal-set "super hard" --plane-model --code-version mani_71 --gamma 0.6 --reward-type "dense potential"
#python train.py --train --headless-mode --goal-set "super hard" --eval-goal-set "super hard" --plane-model --code-version mani_72 --gamma 0.95 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "super hard" --eval-goal-set "super hard" --plane-model --code-version mani_73 --gamma 0.8 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "super hard" --eval-goal-set "super hard" --plane-model --code-version mani_74 --gamma 0.6 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_75 --gamma 0.95 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_76 --gamma 0.95 --reward-type "dense distance"

#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_77 --gamma 0.95 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_78 --gamma 0.8 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_79 --gamma 0.6 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_80 --gamma 0.95 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_81 --gamma 0.8 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_82 --gamma 0.6 --reward-type "dense distance"

#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_83 --gamma 0.95 --reward-type "dense potential"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_84 --gamma 0.8 --reward-type "dense potential"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_85 --gamma 0.6 --reward-type "dense potential"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_86 --gamma 0.86 --reward-type "dense potential"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_87 --gamma 0.87 --reward-type "dense potential"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_88 --gamma 0.88 --reward-type "dense potential"

#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_89 --gamma 0.95 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_90 --gamma 0.8 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_91 --gamma 0.6 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_92 --gamma 0.95 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_93 --gamma 0.8 --reward-type "dense distance"
#python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_94 --gamma 0.6 --reward-type "dense distance"

python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_95 --gamma 0.95 --reward-type "dense potential"
python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_96 --gamma 0.8 --reward-type "dense potential"
python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --plane-model --code-version mani_97 --gamma 0.6 --reward-type "dense potential"
python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_98 --gamma 0.95 --reward-type "dense potential"
python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_99 --gamma 0.8 --reward-type "dense potential"
python train.py --train --headless-mode --goal-set "hard" --eval-goal-set "hard" --code-version mani_100 --gamma 0.6 --reward-type "dense potential"

